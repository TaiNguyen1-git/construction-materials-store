# TÃ i Liá»‡u Ká»¹ Thuáº­t: Há»‡ Thá»‘ng PhÃ¢n TÃ­ch Xu HÆ°á»›ng Thá»‹ TrÆ°á»ng (Market Trend Analysis)

## Tá»•ng Quan

### Má»¥c TiÃªu
XÃ¢y dá»±ng há»‡ thá»‘ng thu tháº­p, phÃ¢n tÃ­ch vÃ  dá»± bÃ¡o xu hÆ°á»›ng giÃ¡ váº­t liá»‡u xÃ¢y dá»±ng, giÃºp doanh nghiá»‡p Ä‘Æ°a ra quyáº¿t Ä‘á»‹nh nháº­p hÃ ng, Ä‘á»‹nh giÃ¡ vÃ  chiáº¿n lÆ°á»£c kinh doanh chÃ­nh xÃ¡c.

### Pháº¡m Vi
- **Nguá»“n dá»¯ liá»‡u**: Web scraping tá»« cÃ¡c nguá»“n cÃ´ng khai
- **Loáº¡i dá»¯ liá»‡u**: GiÃ¡ VLXD, tin tá»©c ngÃ nh, chá»‰ sá»‘ kinh táº¿
- **Táº§n suáº¥t**: Cáº­p nháº­t hÃ ng ngÃ y
- **Dá»± bÃ¡o**: 1-3 thÃ¡ng tá»›i

### Kiáº¿n TrÃºc Tá»•ng Thá»ƒ

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              MARKET TREND ANALYSIS SYSTEM                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚  [Data Collection Layer]                                    â”‚
â”‚       â”œâ”€â”€ Price Scraper (daily)                             â”‚
â”‚       â”œâ”€â”€ News Scraper (daily)                              â”‚
â”‚       â””â”€â”€ Economic Indicators API                           â”‚
â”‚                     â”‚                                       â”‚
â”‚                     â†“                                       â”‚
â”‚  [Data Processing Layer]                                    â”‚
â”‚       â”œâ”€â”€ Data cleaning & validation                        â”‚
â”‚       â”œâ”€â”€ Price normalization                               â”‚
â”‚       â””â”€â”€ Feature extraction                                â”‚
â”‚                     â”‚                                       â”‚
â”‚                     â†“                                       â”‚
â”‚  [Analysis Layer]                                           â”‚
â”‚       â”œâ”€â”€ Time Series Analysis                              â”‚
â”‚       â”œâ”€â”€ Trend Detection                                   â”‚
â”‚       â”œâ”€â”€ Anomaly Detection                                 â”‚
â”‚       â””â”€â”€ Sentiment Analysis (news)                         â”‚
â”‚                     â”‚                                       â”‚
â”‚                     â†“                                       â”‚
â”‚  [Forecasting Layer]                                        â”‚
â”‚       â”œâ”€â”€ ARIMA / Prophet                                   â”‚
â”‚       â””â”€â”€ Ensemble predictions                              â”‚
â”‚                     â”‚                                       â”‚
â”‚                     â†“                                       â”‚
â”‚  [Output Layer]                                             â”‚
â”‚       â”œâ”€â”€ Price trend charts                                â”‚
â”‚       â”œâ”€â”€ Alerts & notifications                            â”‚
â”‚       â””â”€â”€ Recommendations                                   â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Nguá»“n Dá»¯ Liá»‡u

### 1. Nguá»“n GiÃ¡ VLXD

| Nguá»“n | URL | Táº§n suáº¥t | Dá»¯ liá»‡u |
|-------|-----|----------|---------|
| **Bá»™ XÃ¢y Dá»±ng** | giavlxd.xaydung.gov.vn | HÃ ng tuáº§n | GiÃ¡ tham kháº£o chÃ­nh thá»©c |
| **VLXD.com** | vlxd.com.vn | HÃ ng ngÃ y | GiÃ¡ thá»‹ trÆ°á»ng |
| **ThÃ©p Online** | steelonline.vn | HÃ ng ngÃ y | GiÃ¡ thÃ©p |
| **BÃ¡o giÃ¡ NCC** | Nhiá»u nguá»“n | Theo Ä‘á»£t | GiÃ¡ tá»« nhÃ  cung cáº¥p |

### 2. Nguá»“n Tin Tá»©c

| Nguá»“n | Loáº¡i | Má»¥c Ä‘Ã­ch |
|-------|------|----------|
| vnexpress.net | Kinh táº¿ | Tin vÄ© mÃ´ |
| cafef.vn | TÃ i chÃ­nh | GiÃ¡ nguyÃªn liá»‡u tháº¿ giá»›i |
| baoxaydung.com.vn | NgÃ nh | Tin xÃ¢y dá»±ng |
| batdongsan.com.vn | BÄS | Dá»± Ã¡n má»›i |

### 3. Chá»‰ Sá»‘ Kinh Táº¿

| Indicator | Nguá»“n | áº¢nh hÆ°á»Ÿng |
|-----------|-------|-----------|
| CPI | GSO | Láº¡m phÃ¡t â†’ giÃ¡ VLXD |
| Tá»· giÃ¡ USD | NHNN | GiÃ¡ nháº­p kháº©u |
| GiÃ¡ dáº§u tháº¿ giá»›i | Reuters | Chi phÃ­ váº­n chuyá»ƒn |
| GiÃ¡ thÃ©p tháº¿ giá»›i | LME | GiÃ¡ thÃ©p trong nÆ°á»›c |

---

## Web Scraping System

### Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    SCRAPING SYSTEM                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚  [GitHub Actions]                                           â”‚
â”‚       â”‚  Schedule: 0 6 * * * (6AM daily)                    â”‚
â”‚       â”‚                                                     â”‚
â”‚       â†“                                                     â”‚
â”‚  [Python Scraper]                                           â”‚
â”‚       â”‚                                                     â”‚
â”‚       â”œâ”€â”€ requests + BeautifulSoup (static pages)           â”‚
â”‚       â”œâ”€â”€ Selenium (JS-rendered pages)                      â”‚
â”‚       â””â”€â”€ Rate limiting (1 req/3s)                          â”‚
â”‚                     â”‚                                       â”‚
â”‚                     â†“                                       â”‚
â”‚  [Data Validation]                                          â”‚
â”‚       â”œâ”€â”€ Schema validation                                 â”‚
â”‚       â”œâ”€â”€ Outlier detection                                 â”‚
â”‚       â””â”€â”€ Duplicate check                                   â”‚
â”‚                     â”‚                                       â”‚
â”‚                     â†“                                       â”‚
â”‚  [MongoDB Atlas]                                            â”‚
â”‚       â””â”€â”€ Collection: market_prices                         â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Scraper Code Structure

```python
# scrapers/price_scraper.py

import requests
from bs4 import BeautifulSoup
from datetime import datetime
import time

class VLXDPriceScraper:
    def __init__(self):
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) ...',
            'Accept-Language': 'vi-VN,vi;q=0.9'
        }
        self.delay = 3  # seconds between requests
    
    def scrape_cement_prices(self):
        """Scrape cement prices from source"""
        url = "https://example.com/gia-xi-mang"
        
        try:
            response = requests.get(url, headers=self.headers, timeout=30)
            response.raise_for_status()
            
            soup = BeautifulSoup(response.text, 'html.parser')
            
            prices = []
            for row in soup.select('.price-table tbody tr'):
                product_name = row.select_one('.product-name').text.strip()
                price_text = row.select_one('.price').text.strip()
                
                price = self.parse_price(price_text)
                
                prices.append({
                    'product': product_name,
                    'category': 'cement',
                    'price': price,
                    'unit': 'VND/bao',
                    'source': 'example.com',
                    'scraped_at': datetime.utcnow()
                })
            
            return prices
            
        except Exception as e:
            print(f"Error scraping: {e}")
            return []
    
    def parse_price(self, text):
        """Parse Vietnamese price format"""
        # "95.000Ä‘" -> 95000
        clean = text.replace('.', '').replace(',', '').replace('Ä‘', '').strip()
        return int(clean)
```

### Data Schema

```python
price_record = {
    "_id": ObjectId,
    "product_name": str,          # "Xi mÄƒng Holcim PCB40"
    "category": str,              # "cement"
    "brand": str,                 # "Holcim"
    "price": float,               # 95000
    "unit": str,                  # "VND/bao"
    "region": str,                # "Dong Nai"
    "source": str,                # "giavlxd.xaydung.gov.vn"
    "source_url": str,
    "scraped_at": datetime,
    "valid_from": datetime,
    "valid_to": datetime,
    "metadata": {
        "spec": str,              # "PCB40 50kg"
        "min_quantity": int,
        "delivery_included": bool
    }
}
```

---

## Time Series Analysis

### 1. Trend Detection

```python
def detect_trend(prices, window=7):
    """
    Detect price trend using moving average
    
    Returns: 'UP', 'DOWN', 'STABLE'
    """
    if len(prices) < window * 2:
        return 'INSUFFICIENT_DATA'
    
    # Calculate short-term and long-term MA
    short_ma = np.mean(prices[-window:])
    long_ma = np.mean(prices[-window*2:-window])
    
    change_percent = (short_ma - long_ma) / long_ma * 100
    
    if change_percent > 3:
        return 'UP'
    elif change_percent < -3:
        return 'DOWN'
    else:
        return 'STABLE'
```

### 2. Seasonality Analysis

```python
from statsmodels.tsa.seasonal import seasonal_decompose

def analyze_seasonality(price_series, period=30):
    """
    Decompose price series into trend, seasonal, and residual
    """
    result = seasonal_decompose(price_series, model='multiplicative', period=period)
    
    return {
        'trend': result.trend,
        'seasonal': result.seasonal,
        'residual': result.resid,
        'seasonal_strength': calculate_seasonal_strength(result)
    }
```

### 3. Anomaly Detection

```python
def detect_price_anomaly(current_price, historical_prices, threshold=2.5):
    """
    Detect if current price is an anomaly using Z-score
    """
    mean = np.mean(historical_prices)
    std = np.std(historical_prices)
    
    z_score = (current_price - mean) / std
    
    if abs(z_score) > threshold:
        direction = 'HIGH' if z_score > 0 else 'LOW'
        return {
            'is_anomaly': True,
            'z_score': z_score,
            'direction': direction,
            'expected_range': (mean - threshold*std, mean + threshold*std)
        }
    
    return {'is_anomaly': False}
```

---

## Forecasting Models

### 1. ARIMA (AutoRegressive Integrated Moving Average)

```python
from statsmodels.tsa.arima.model import ARIMA

def forecast_arima(prices, periods=30):
    """
    Forecast prices using ARIMA model
    """
    # Fit model (p, d, q parameters)
    model = ARIMA(prices, order=(2, 1, 2))
    fitted = model.fit()
    
    # Forecast
    forecast = fitted.forecast(steps=periods)
    conf_int = fitted.get_forecast(steps=periods).conf_int()
    
    return {
        'forecast': forecast.tolist(),
        'lower_bound': conf_int.iloc[:, 0].tolist(),
        'upper_bound': conf_int.iloc[:, 1].tolist(),
        'model': 'ARIMA(2,1,2)',
        'aic': fitted.aic
    }
```

### 2. Prophet (Facebook)

```python
from prophet import Prophet

def forecast_prophet(df, periods=30):
    """
    Forecast using Prophet
    
    df: DataFrame with columns 'ds' (date) and 'y' (price)
    """
    model = Prophet(
        yearly_seasonality=True,
        weekly_seasonality=False,
        daily_seasonality=False,
        changepoint_prior_scale=0.05
    )
    
    model.fit(df)
    
    future = model.make_future_dataframe(periods=periods)
    forecast = model.predict(future)
    
    return {
        'forecast': forecast[['ds', 'yhat', 'yhat_lower', 'yhat_upper']].tail(periods),
        'trend': forecast['trend'].tolist(),
        'model': 'Prophet'
    }
```

### 3. Ensemble Forecast

```python
def ensemble_forecast(prices, periods=30):
    """
    Combine multiple models for robust forecast
    """
    arima_forecast = forecast_arima(prices, periods)
    prophet_forecast = forecast_prophet(prices, periods)
    
    # Weighted average (adjustable based on historical accuracy)
    weights = {'arima': 0.4, 'prophet': 0.6}
    
    ensemble = []
    for i in range(periods):
        combined = (weights['arima'] * arima_forecast['forecast'][i] +
                    weights['prophet'] * prophet_forecast['forecast'][i])
        ensemble.append(combined)
    
    return {
        'forecast': ensemble,
        'models_used': ['ARIMA', 'Prophet'],
        'weights': weights
    }
```

---

## News Sentiment Analysis

### Workflow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  NEWS ANALYSIS PIPELINE                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚  [Scrape News]                                              â”‚
â”‚       â”‚ Keywords: "giÃ¡ thÃ©p", "giÃ¡ xi mÄƒng", "VLXD"         â”‚
â”‚       â”‚                                                     â”‚
â”‚       â†“                                                     â”‚
â”‚  [Extract Entities]                                         â”‚
â”‚       â”‚ Products: thÃ©p, xi mÄƒng, cÃ¡t, Ä‘Ã¡                    â”‚
â”‚       â”‚ Actions: tÄƒng, giáº£m, á»•n Ä‘á»‹nh                        â”‚
â”‚       â”‚ Numbers: +5%, 100,000Ä‘                              â”‚
â”‚       â”‚                                                     â”‚
â”‚       â†“                                                     â”‚
â”‚  [Sentiment Analysis]                                       â”‚
â”‚       â”‚ Bearish: giÃ¡ giáº£m, nguá»“n cung dá»“i dÃ o               â”‚
â”‚       â”‚ Bullish: giÃ¡ tÄƒng, thiáº¿u há»¥t, nhu cáº§u cao           â”‚
â”‚       â”‚                                                     â”‚
â”‚       â†“                                                     â”‚
â”‚  [Market Signal]                                            â”‚
â”‚       â””â”€â”€ "ThÃ©p: BULLISH (3 tin tÄƒng giÃ¡ trong 7 ngÃ y)"     â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Signal Generation

```python
def generate_market_signal(product_category, news_items):
    """
    Generate market signal from news sentiment
    """
    bullish_keywords = ['tÄƒng', 'cao', 'thiáº¿u há»¥t', 'nhu cáº§u', 'khan hiáº¿m']
    bearish_keywords = ['giáº£m', 'tháº¥p', 'dÆ° thá»«a', 'giáº£m cáº§u', 'tá»“n kho']
    
    bullish_count = 0
    bearish_count = 0
    
    for news in news_items:
        text = news['title'] + ' ' + news['summary']
        
        for word in bullish_keywords:
            if word in text.lower():
                bullish_count += 1
                
        for word in bearish_keywords:
            if word in text.lower():
                bearish_count += 1
    
    if bullish_count > bearish_count + 2:
        return 'BULLISH'
    elif bearish_count > bullish_count + 2:
        return 'BEARISH'
    else:
        return 'NEUTRAL'
```

---

## API Specification

### Endpoint: Get Price Trends

```
GET /api/market/trends?category=cement&period=30d
```

### Response

```json
{
  "success": true,
  "data": {
    "category": "cement",
    "period": "30d",
    "summary": {
      "trend": "UP",
      "changePercent": 5.2,
      "currentAvgPrice": 98500,
      "previousAvgPrice": 93600
    },
    "priceHistory": [
      { "date": "2025-12-10", "avgPrice": 93000, "minPrice": 91000, "maxPrice": 96000 },
      { "date": "2025-12-17", "avgPrice": 95000, "minPrice": 93000, "maxPrice": 98000 },
      ...
    ],
    "forecast": {
      "next30Days": {
        "prediction": 102000,
        "lowerBound": 98000,
        "upperBound": 106000,
        "confidence": 0.75
      }
    },
    "signals": {
      "technical": "UP",
      "news": "BULLISH",
      "combined": "STRONG_BUY"
    },
    "recommendation": "GiÃ¡ xi mÄƒng dá»± kiáº¿n tÄƒng 3-5% trong 30 ngÃ y tá»›i. Äá» xuáº¥t tÄƒng stock."
  }
}
```

### Endpoint: Get Alerts

```
GET /api/market/alerts?active=true
```

### Response

```json
{
  "success": true,
  "data": {
    "alerts": [
      {
        "id": "alert_001",
        "type": "PRICE_SPIKE",
        "severity": "HIGH",
        "product": "ThÃ©p HÃ²a PhÃ¡t D10",
        "message": "GiÃ¡ tÄƒng 8% trong 7 ngÃ y, cao hÆ¡n 2.5 std so vá»›i trung bÃ¬nh",
        "currentPrice": 19500,
        "expectedPrice": 18000,
        "createdAt": "2026-01-08T06:00:00Z",
        "actions": ["Review pricing", "Check competitor"]
      }
    ]
  }
}
```

---

## Dashboard Visualization

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ğŸ“ˆ MARKET TRENDS DASHBOARD                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                            â”‚
â”‚  [Price Trend Chart - 30 Days]                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚  â”‚     â•±â•²                                  â•±â•²     â”‚        â”‚
â”‚  â”‚    â•±  â•²    ___                        â•±  â•²    â”‚        â”‚
â”‚  â”‚   â•±    â•²__â•±   â•²____          ________â•±    â•²   â”‚        â”‚
â”‚  â”‚  â•±                  â•²________â•±               â”‚        â”‚
â”‚  â”‚ â•±                                             â”‚        â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â”‚    Xi mÄƒng â–²+5.2%  |  ThÃ©p â–²+3.1%  |  CÃ¡t â–¼-1.2%          â”‚
â”‚                                                            â”‚
â”‚  ğŸ”® FORECAST (30 days):                                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
â”‚  â”‚ Xi mÄƒng      â”‚ ThÃ©p         â”‚ CÃ¡t          â”‚           â”‚
â”‚  â”‚ â–² +3-5%      â”‚ â–² +2-4%      â”‚ â”€ Â±1%        â”‚           â”‚
â”‚  â”‚ Conf: 75%   â”‚ Conf: 70%   â”‚ Conf: 85%   â”‚           â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
â”‚                                                            â”‚
â”‚  âš ï¸ ALERTS:                                                â”‚
â”‚  â€¢ ThÃ©p HÃ²a PhÃ¡t: GiÃ¡ tÄƒng báº¥t thÆ°á»ng (+8%)               â”‚
â”‚  â€¢ Tin tá»©c: 3 bÃ i vá» thiáº¿u há»¥t xi mÄƒng miá»n Nam           â”‚
â”‚                                                            â”‚
â”‚  ğŸ“° LATEST NEWS:                                           â”‚
â”‚  â€¢ "GiÃ¡ thÃ©p tháº¿ giá»›i tÄƒng do cáº§u Trung Quá»‘c" - VnExpress â”‚
â”‚  â€¢ "Dá»± Ã¡n háº¡ táº§ng 2026 Ä‘áº©y nhu cáº§u VLXD" - CafeF          â”‚
â”‚                                                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Technology Stack

### Python Libraries

| Library | Version | Purpose |
|---------|---------|---------|
| requests | 2.31.x | HTTP requests |
| beautifulsoup4 | 4.12.x | HTML parsing |
| selenium | 4.15.x | Dynamic pages |
| pandas | 2.0.x | Data processing |
| statsmodels | 0.14.x | ARIMA |
| prophet | 1.1.x | Forecasting |
| Flask | 3.0.x | API server |
| pymongo | 4.5.x | MongoDB driver |

### Infrastructure

| Component | Platform | Schedule |
|-----------|----------|----------|
| Scraper | GitHub Actions | Daily 6AM |
| ML API | Render Free | On-demand |
| Database | MongoDB Atlas | Always-on |
| Alerts | GitHub Actions | Every 4 hours |

---

## Ethical & Legal Considerations

### Web Scraping Guidelines

1. **Respect robots.txt**: Check and follow robots.txt rules
2. **Rate limiting**: Maximum 1 request per 3 seconds
3. **User-Agent**: Use honest, identifiable user agent
4. **Data usage**: Only for internal business intelligence
5. **No login bypass**: Only scrape public data
6. **Attribution**: Cite sources in reports

### Data Privacy

- No personal data collection
- Only aggregate market data
- Comply with website terms of service

---

## Metrics & Evaluation

### Forecasting Accuracy

| Metric | Target | Description |
|--------|--------|-------------|
| MAPE | < 10% | Mean Absolute Percentage Error |
| RMSE | < 5000 | Root Mean Square Error (VND) |
| Direction Accuracy | > 70% | ÄÃºng hÆ°á»›ng tÄƒng/giáº£m |

### Business Metrics

| Metric | Measurement |
|--------|-------------|
| Inventory Optimization | Reduce overstock by 15% |
| Procurement Timing | Buy 3-5% cheaper on average |
| Alert Usefulness | 80% alerts actionable |

---

## Æ¯u Äiá»ƒm & Háº¡n Cháº¿

### Æ¯u Äiá»ƒm
1. **Proactive**: Biáº¿t trÆ°á»›c xu hÆ°á»›ng giÃ¡
2. **Data-driven**: Quyáº¿t Ä‘á»‹nh dá»±a trÃªn dá»¯ liá»‡u
3. **Competitive advantage**: Mua hÃ ng Ä‘Ãºng thá»i Ä‘iá»ƒm
4. **Automated**: Cáº­p nháº­t tá»± Ä‘á»™ng hÃ ng ngÃ y

### Háº¡n Cháº¿
1. **Scraping fragility**: Website thay Ä‘á»•i â†’ scraper há»ng
2. **External factors**: KhÃ´ng dá»± Ä‘oÃ¡n Ä‘Æ°á»£c thiÃªn tai, chÃ­nh sÃ¡ch
3. **Data quality**: Phá»¥ thuá»™c vÃ o nguá»“n dá»¯ liá»‡u
4. **Maintenance**: Cáº§n maintain scraper thÆ°á»ng xuyÃªn

---

*TÃ i liá»‡u Ä‘Æ°á»£c táº¡o: 08/01/2026*
*PhiÃªn báº£n: 1.0*
