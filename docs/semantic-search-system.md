# TÃ i Liá»‡u Ká»¹ Thuáº­t: Há»‡ Thá»‘ng TÃ¬m Kiáº¿m Ngá»¯ NghÄ©a (Semantic Search)

## Tá»•ng Quan

### Má»¥c TiÃªu
XÃ¢y dá»±ng há»‡ thá»‘ng tÃ¬m kiáº¿m thÃ´ng minh cÃ³ kháº£ nÄƒng hiá»ƒu ngá»¯ nghÄ©a truy váº¥n cá»§a ngÆ°á»i dÃ¹ng, khÃ´ng chá»‰ dá»±a vÃ o tá»« khÃ³a chÃ­nh xÃ¡c, giÃºp tÃ¬m Ä‘Æ°á»£c sáº£n pháº©m phÃ¹ há»£p ngay cáº£ khi ngÆ°á»i dÃ¹ng khÃ´ng biáº¿t tÃªn chÃ­nh xÃ¡c.

### Váº¥n Äá» Hiá»‡n Táº¡i

```
TÃ¬m kiáº¿m truyá»n thá»‘ng (Keyword-based):

User search: "gáº¡ch chá»‹u lá»­a"
Database:    "Gáº¡ch samot chá»‹u nhiá»‡t", "Gáº¡ch á»‘ng B4"
Result:      âŒ KhÃ´ng tÃ¬m tháº¥y! (vÃ¬ khÃ´ng cÃ³ tá»« "chá»‹u lá»­a")

Váº¥n Ä‘á»:
â€¢ "chá»‹u lá»­a" â‰  "chá»‹u nhiá»‡t" (text matching tháº¥t báº¡i)
â€¢ User khÃ´ng biáº¿t "samot" lÃ  loáº¡i gáº¡ch chá»‹u nhiá»‡t
â€¢ Máº¥t khÃ¡ch hÃ ng vÃ¬ khÃ´ng tÃ¬m Ä‘Æ°á»£c sáº£n pháº©m
```

### Giáº£i PhÃ¡p: Semantic Search

```
User search: "gáº¡ch chá»‹u lá»­a"
           â†“ Embedding
Vector A:  [0.23, 0.85, 0.12, 0.67, ...]

Database products:
  "Gáº¡ch samot" â†’ Vector B: [0.21, 0.82, 0.15, 0.65, ...]
  "Gáº¡ch á»‘ng B4" â†’ Vector C: [0.19, 0.78, 0.18, 0.62, ...]

Similarity:
  cos(A, B) = 0.92 âœ“ (ráº¥t giá»‘ng!)
  cos(A, C) = 0.85 âœ“ (khÃ¡ giá»‘ng)

Result: âœ… TÃ¬m tháº¥y cáº£ hai!
```

### Kiáº¿n TrÃºc Tá»•ng Thá»ƒ

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  SEMANTIC SEARCH SYSTEM                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚  [User Query] "gáº¡ch chá»‹u lá»­a giÃ¡ ráº»"                        â”‚
â”‚       â”‚                                                     â”‚
â”‚       â†“                                                     â”‚
â”‚  [Query Processing]                                         â”‚
â”‚       â”œâ”€â”€ Query expansion (synonyms)                        â”‚
â”‚       â”œâ”€â”€ Intent detection                                  â”‚
â”‚       â””â”€â”€ Filter extraction (giÃ¡ ráº» â†’ sort by price)        â”‚
â”‚                     â”‚                                       â”‚
â”‚                     â†“                                       â”‚
â”‚  [Embedding Model]                                          â”‚
â”‚       â””â”€â”€ Gemini text-embedding-004                         â”‚
â”‚           Output: 768-dimensional vector                    â”‚
â”‚                     â”‚                                       â”‚
â”‚                     â†“                                       â”‚
â”‚  [Vector Search]                                            â”‚
â”‚       â””â”€â”€ Cosine similarity vá»›i product vectors             â”‚
â”‚                     â”‚                                       â”‚
â”‚                     â†“                                       â”‚
â”‚  [Re-ranking]                                               â”‚
â”‚       â”œâ”€â”€ Combine semantic score + keyword score            â”‚
â”‚       â”œâ”€â”€ Apply filters (price, category, stock)            â”‚
â”‚       â””â”€â”€ Boost by relevance factors                        â”‚
â”‚                     â”‚                                       â”‚
â”‚                     â†“                                       â”‚
â”‚  [Results]                                                  â”‚
â”‚       â””â”€â”€ Ranked list of products                           â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Embedding Model

### Lá»±a Chá»n Model

| Model | Dimension | Tiáº¿ng Viá»‡t | Cost | Recommendation |
|-------|-----------|------------|------|----------------|
| **Gemini text-embedding-004** | 768 | âœ… Tá»‘t | Free tier cÃ³ | â­ Recommended |
| OpenAI text-embedding-3-small | 1536 | âœ… Tá»‘t | Paid | Alternative |
| Sentence-BERT (multilingual) | 768 | âš ï¸ KhÃ¡ | Free | Self-hosted |
| PhoBERT | 768 | âœ… Ráº¥t tá»‘t | Free | Vietnamese-specific |

### Gemini Embedding Integration

```python
from google.generativeai import GenerativeModel
import google.generativeai as genai

genai.configure(api_key=GEMINI_API_KEY)

def get_embedding(text: str) -> list[float]:
    """
    Get embedding vector for text using Gemini
    """
    model = genai.GenerativeModel('models/text-embedding-004')
    result = genai.embed_content(
        model='models/text-embedding-004',
        content=text,
        task_type="retrieval_document"
    )
    return result['embedding']  # 768-dimensional vector

# Example
query_embedding = get_embedding("gáº¡ch chá»‹u lá»­a")
# Output: [0.023, -0.156, 0.089, ..., 0.045]  # 768 floats
```

### TypeScript Implementation (Next.js)

```typescript
// lib/embedding-service.ts

import { GoogleGenerativeAI } from '@google/generative-ai';

const genai = new GoogleGenerativeAI(process.env.GEMINI_API_KEY!);

export class EmbeddingService {
  private model = genai.getGenerativeModel({ model: 'text-embedding-004' });

  async getEmbedding(text: string): Promise<number[]> {
    const result = await this.model.embedContent(text);
    return result.embedding.values;
  }

  async batchEmbed(texts: string[]): Promise<number[][]> {
    const embeddings = await Promise.all(
      texts.map(text => this.getEmbedding(text))
    );
    return embeddings;
  }
}
```

---

## Vector Storage & Search

### Option 1: In-Memory (Simple, for small catalog)

```typescript
// lib/vector-store.ts

interface VectorEntry {
  id: string;
  productId: string;
  text: string;
  embedding: number[];
  metadata: {
    name: string;
    category: string;
    price: number;
  };
}

class InMemoryVectorStore {
  private vectors: VectorEntry[] = [];

  add(entry: VectorEntry) {
    this.vectors.push(entry);
  }

  search(queryVector: number[], topK: number = 10): VectorEntry[] {
    const scored = this.vectors.map(entry => ({
      entry,
      score: this.cosineSimilarity(queryVector, entry.embedding)
    }));

    return scored
      .sort((a, b) => b.score - a.score)
      .slice(0, topK)
      .map(s => s.entry);
  }

  private cosineSimilarity(a: number[], b: number[]): number {
    let dotProduct = 0;
    let normA = 0;
    let normB = 0;

    for (let i = 0; i < a.length; i++) {
      dotProduct += a[i] * b[i];
      normA += a[i] * a[i];
      normB += b[i] * b[i];
    }

    return dotProduct / (Math.sqrt(normA) * Math.sqrt(normB));
  }
}
```

### Option 2: MongoDB Atlas Vector Search

```javascript
// MongoDB Atlas Search Index Configuration
{
  "mappings": {
    "dynamic": true,
    "fields": {
      "embedding": {
        "type": "knnVector",
        "dimensions": 768,
        "similarity": "cosine"
      }
    }
  }
}

// Aggregation Pipeline for Vector Search
db.products.aggregate([
  {
    "$vectorSearch": {
      "index": "product_embeddings",
      "path": "embedding",
      "queryVector": [0.023, -0.156, ...],  // Query embedding
      "numCandidates": 100,
      "limit": 10
    }
  },
  {
    "$project": {
      "name": 1,
      "price": 1,
      "score": { "$meta": "vectorSearchScore" }
    }
  }
])
```

### Option 3: Pinecone (Scalable, managed)

```typescript
import { Pinecone } from '@pinecone-database/pinecone';

const pinecone = new Pinecone({
  apiKey: process.env.PINECONE_API_KEY!
});

const index = pinecone.index('products');

// Upsert vectors
await index.upsert([
  {
    id: 'prod_001',
    values: embedding,  // 768-dim vector
    metadata: {
      name: 'Gáº¡ch samot chá»‹u nhiá»‡t',
      category: 'gach',
      price: 85000
    }
  }
]);

// Query
const results = await index.query({
  vector: queryEmbedding,
  topK: 10,
  includeMetadata: true
});
```

---

## CÃ´ng Thá»©c TÃ­nh ToÃ¡n

### 1. Cosine Similarity

```
                    A Â· B           Î£(Ai Ã— Bi)
cos(Î¸) = â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ = â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
          â€–Aâ€– Ã— â€–Bâ€–             âˆšÎ£(AiÂ²) Ã— âˆšÎ£(BiÂ²)

Káº¿t quáº£: -1 Ä‘áº¿n 1
  1.0  = Identical
  0.7+ = Very similar
  0.5+ = Similar
  0.3+ = Somewhat related
  <0.3 = Not related
```

### 2. Hybrid Score (Semantic + Keyword)

```
Hybrid_Score = Î± Ã— Semantic_Score + Î² Ã— Keyword_Score + Î³ Ã— Boost_Factors

Weights:
  Î± = 0.60 (Semantic similarity)
  Î² = 0.25 (Keyword matching)
  Î³ = 0.15 (Boost factors)

Keyword_Score = matched_terms / query_terms

Boost_Factors:
  + 0.1 if exact_name_match
  + 0.05 if in_stock
  + 0.05 if has_image
  - 0.1 if out_of_stock
```

### 3. Query Expansion

```python
SYNONYMS = {
    'chá»‹u lá»­a': ['chá»‹u nhiá»‡t', 'refractory', 'samot'],
    'thÃ©p': ['sáº¯t', 'steel', 'inox'],
    'xi mÄƒng': ['cement', 'ximang', 'xm'],
    'ráº»': ['giÃ¡ ráº»', 'tiáº¿t kiá»‡m', 'pháº£i chÄƒng'],
    'tá»‘t': ['cháº¥t lÆ°á»£ng', 'bá»n', 'Ä‘áº£m báº£o']
}

def expand_query(query: str) -> list[str]:
    """Expand query with synonyms"""
    expanded = [query]
    
    for term, synonyms in SYNONYMS.items():
        if term in query.lower():
            for syn in synonyms:
                expanded.append(query.lower().replace(term, syn))
    
    return list(set(expanded))

# Example
expand_query("gáº¡ch chá»‹u lá»­a")
# Output: ["gáº¡ch chá»‹u lá»­a", "gáº¡ch chá»‹u nhiá»‡t", "gáº¡ch samot", "gáº¡ch refractory"]
```

---

## VÃ­ Dá»¥ TÃ­nh ToÃ¡n

### Scenario

```
User Query: "xi mÄƒng chá»‘ng tháº¥m giÃ¡ ráº»"

Step 1: Query Expansion
  Expanded: ["xi mÄƒng chá»‘ng tháº¥m giÃ¡ ráº»", "cement chá»‘ng tháº¥m", "xi mÄƒng waterproof"]

Step 2: Get Query Embedding
  query_vector = [0.15, -0.23, 0.45, ..., 0.08]  # 768 dims

Step 3: Search Products
  Product A: "Xi mÄƒng chá»‘ng tháº¥m Sika"
    embedding = [0.14, -0.21, 0.43, ..., 0.09]
    semantic_score = cosine(query, A) = 0.92

  Product B: "Xi mÄƒng Holcim PCB40"
    embedding = [0.12, -0.18, 0.38, ..., 0.11]
    semantic_score = cosine(query, B) = 0.71

  Product C: "SÆ¡n chá»‘ng tháº¥m Jotun"
    embedding = [0.08, -0.25, 0.52, ..., 0.05]
    semantic_score = cosine(query, C) = 0.58

Step 4: Calculate Hybrid Score
  Product A:
    semantic = 0.92
    keyword = 4/4 = 1.0 (all terms match)
    boost = 0.05 (in_stock)
    hybrid = 0.60Ã—0.92 + 0.25Ã—1.0 + 0.15Ã—0.05 = 0.8095

  Product B:
    semantic = 0.71
    keyword = 2/4 = 0.5 (xi mÄƒng matches)
    boost = 0.05
    hybrid = 0.60Ã—0.71 + 0.25Ã—0.5 + 0.15Ã—0.05 = 0.5585

  Product C:
    semantic = 0.58
    keyword = 2/4 = 0.5 (chá»‘ng tháº¥m matches)
    boost = 0.05
    hybrid = 0.60Ã—0.58 + 0.25Ã—0.5 + 0.15Ã—0.05 = 0.4805

Step 5: Final Ranking
  1. Xi mÄƒng chá»‘ng tháº¥m Sika (0.81) âœ…
  2. Xi mÄƒng Holcim PCB40 (0.56)
  3. SÆ¡n chá»‘ng tháº¥m Jotun (0.48)
```

---

## API Specification

### Endpoint: Semantic Search

```
GET /api/search?q=xi+mÄƒng+chá»‘ng+tháº¥m&limit=20
```

### Request Parameters

| Parameter | Type | Default | Description |
|-----------|------|---------|-------------|
| q | string | required | Search query |
| limit | number | 20 | Max results |
| category | string | null | Filter by category |
| minPrice | number | null | Minimum price |
| maxPrice | number | null | Maximum price |
| inStock | boolean | false | Only in-stock items |

### Response

```json
{
  "success": true,
  "data": {
    "query": "xi mÄƒng chá»‘ng tháº¥m",
    "totalResults": 15,
    "searchType": "semantic",
    "results": [
      {
        "productId": "prod_001",
        "name": "Xi mÄƒng chá»‘ng tháº¥m Sika",
        "category": "xi_mang",
        "price": 125000,
        "image": "/images/sika-waterproof.jpg",
        "inStock": true,
        "score": 0.81,
        "scoreBreakdown": {
          "semantic": 0.92,
          "keyword": 1.0,
          "boost": 0.05
        },
        "matchedTerms": ["xi mÄƒng", "chá»‘ng tháº¥m"],
        "highlight": "<em>Xi mÄƒng</em> <em>chá»‘ng tháº¥m</em> Sika"
      },
      ...
    ],
    "suggestions": [
      "xi mÄƒng chá»‘ng tháº¥m sika",
      "keo chá»‘ng tháº¥m",
      "sÆ¡n chá»‘ng tháº¥m"
    ],
    "facets": {
      "categories": [
        { "name": "Xi mÄƒng", "count": 8 },
        { "name": "Phá»¥ gia", "count": 5 },
        { "name": "SÆ¡n", "count": 2 }
      ],
      "priceRanges": [
        { "range": "0-100k", "count": 3 },
        { "range": "100k-200k", "count": 8 },
        { "range": "200k+", "count": 4 }
      ]
    }
  }
}
```

---

## Indexing Pipeline

### Product Indexing Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  INDEXING PIPELINE                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚  [Product Created/Updated]                                  â”‚
â”‚       â”‚                                                     â”‚
â”‚       â†“                                                     â”‚
â”‚  [Generate Searchable Text]                                 â”‚
â”‚       â”‚                                                     â”‚
â”‚       â”‚  searchable_text = f"{name} {category} {brand}      â”‚
â”‚       â”‚                      {description} {specs}"         â”‚
â”‚       â”‚                                                     â”‚
â”‚       â†“                                                     â”‚
â”‚  [Get Embedding]                                            â”‚
â”‚       â”‚                                                     â”‚
â”‚       â”‚  embedding = gemini.embed(searchable_text)          â”‚
â”‚       â”‚                                                     â”‚
â”‚       â†“                                                     â”‚
â”‚  [Store in Vector DB]                                       â”‚
â”‚       â”‚                                                     â”‚
â”‚       â”‚  vectorStore.upsert({                               â”‚
â”‚       â”‚    id: productId,                                   â”‚
â”‚       â”‚    embedding: embedding,                            â”‚
â”‚       â”‚    metadata: { name, price, category, ... }         â”‚
â”‚       â”‚  })                                                 â”‚
â”‚       â”‚                                                     â”‚
â”‚       â†“                                                     â”‚
â”‚  [Update Search Index]                                      â”‚
â”‚       â””â”€â”€ Ready for search!                                 â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Batch Indexing (Initial Setup)

```typescript
async function indexAllProducts() {
  const products = await prisma.product.findMany({
    include: { category: true, brand: true }
  });

  const embeddingService = new EmbeddingService();
  const vectorStore = new VectorStore();

  for (const product of products) {
    const searchableText = [
      product.name,
      product.category?.name,
      product.brand?.name,
      product.description,
      product.specifications
    ].filter(Boolean).join(' ');

    const embedding = await embeddingService.getEmbedding(searchableText);

    await vectorStore.upsert({
      id: product.id,
      embedding,
      metadata: {
        name: product.name,
        price: product.price,
        category: product.category?.name,
        inStock: product.stock > 0
      }
    });

    // Rate limit for Gemini API
    await sleep(100);
  }

  console.log(`Indexed ${products.length} products`);
}
```

---

## Search UI Enhancement

### Autocomplete with Semantic Understanding

```typescript
// components/SearchAutocomplete.tsx

export function SearchAutocomplete() {
  const [query, setQuery] = useState('');
  const [suggestions, setSuggestions] = useState([]);

  const debouncedSearch = useDebouncedCallback(async (q: string) => {
    if (q.length < 2) return;

    const res = await fetch(`/api/search/suggest?q=${encodeURIComponent(q)}`);
    const data = await res.json();

    setSuggestions(data.suggestions);
  }, 300);

  return (
    <div className="search-container">
      <input
        type="text"
        value={query}
        onChange={(e) => {
          setQuery(e.target.value);
          debouncedSearch(e.target.value);
        }}
        placeholder="TÃ¬m kiáº¿m sáº£n pháº©m..."
      />
      
      {suggestions.length > 0 && (
        <ul className="suggestions">
          {suggestions.map((s, i) => (
            <li key={i} onClick={() => handleSelect(s)}>
              {s.type === 'product' && <ProductIcon />}
              {s.type === 'category' && <CategoryIcon />}
              <span dangerouslySetInnerHTML={{ __html: s.highlight }} />
            </li>
          ))}
        </ul>
      )}
    </div>
  );
}
```

### "Did You Mean?" Feature

```typescript
function generateDidYouMean(query: string, results: any[]): string | null {
  if (results.length > 5) return null;  // Enough results

  // Find most similar product name
  const topResult = results[0];
  if (topResult && topResult.score < 0.5) {
    // Query might be misspelled
    return topResult.name;
  }

  return null;
}

// Usage in UI
{didYouMean && (
  <p className="did-you-mean">
    CÃ³ pháº£i báº¡n muá»‘n tÃ¬m: 
    <a href={`/search?q=${didYouMean}`}>{didYouMean}</a>?
  </p>
)}
```

---

## Technology Stack

### Libraries & Services

| Component | Technology | Notes |
|-----------|------------|-------|
| Embedding Model | Gemini text-embedding-004 | Free tier available |
| Vector Store | MongoDB Atlas Vector Search | Or Pinecone |
| Text Processing | Underthesea | Vietnamese NLP |
| API | Next.js API Routes | Existing stack |
| Caching | Redis / In-memory | Optional |

### Infrastructure

| Component | Platform | Cost |
|-----------|----------|------|
| Search API | Vercel | Free |
| Vector DB | MongoDB Atlas | Free tier |
| Embedding API | Google AI | Free tier (60 req/min) |

---

## Metrics & Evaluation

### Search Quality Metrics

| Metric | Target | Description |
|--------|--------|-------------|
| MRR (Mean Reciprocal Rank) | > 0.7 | Correct result position |
| Recall@10 | > 85% | % relevant items in top 10 |
| Zero-result Rate | < 5% | Searches with no results |
| Click-through Rate | > 30% | Users clicking results |

### Latency Metrics

| Metric | Target |
|--------|--------|
| P50 Latency | < 200ms |
| P95 Latency | < 500ms |
| P99 Latency | < 1000ms |

### A/B Testing

```
Experiment: Semantic Search vs Keyword Search

Group A (Control): Keyword search only
Group B (Test): Semantic + Keyword hybrid

Metrics to compare:
â€¢ Conversion rate
â€¢ Search-to-purchase rate
â€¢ Zero-result rate
â€¢ User satisfaction (survey)
```

---

## Æ¯u Äiá»ƒm & Háº¡n Cháº¿

### Æ¯u Äiá»ƒm

1. **Hiá»ƒu ngá»¯ nghÄ©a**: "chá»‹u lá»­a" tÃ¬m Ä‘Æ°á»£c "chá»‹u nhiá»‡t"
2. **Typo tolerant**: Sai chÃ­nh táº£ váº«n tÃ¬m Ä‘Æ°á»£c
3. **Multilingual**: TÃ¬m báº±ng tiáº¿ng Viá»‡t hoáº·c tiáº¿ng Anh
4. **Zero-result reduction**: Giáº£m trÆ°á»ng há»£p khÃ´ng tÃ¬m tháº¥y
5. **Better UX**: KhÃ¡ch hÃ ng tÃ¬m Ä‘Æ°á»£c sáº£n pháº©m nhanh hÆ¡n

### Háº¡n Cháº¿

1. **Latency**: Cháº­m hÆ¡n keyword search (thÃªm embedding step)
2. **Cost**: Embedding API cÃ³ giá»›i háº¡n request
3. **Index maintenance**: Cáº§n re-index khi thÃªm sáº£n pháº©m
4. **Cold start**: Cáº§n index toÃ n bá»™ catalog trÆ°á»›c

### So SÃ¡nh

| Aspect | Keyword Search | Semantic Search |
|--------|----------------|-----------------|
| Speed | âš¡ Fast (< 50ms) | ðŸ¢ Medium (200-500ms) |
| Accuracy | âš ï¸ Exact match only | âœ… Understands meaning |
| Synonyms | âŒ No | âœ… Yes |
| Typos | âŒ Fails | âœ… Tolerant |
| Cost | ðŸ’° Free | ðŸ’° API costs |
| Setup | ðŸŸ¢ Easy | ðŸŸ¡ Medium |

---

## Implementation Roadmap

### Phase 1: MVP (1-2 days)
- [ ] Integrate Gemini Embedding API
- [ ] Build in-memory vector store
- [ ] Create search API endpoint
- [ ] Basic UI integration

### Phase 2: Production (3-5 days)
- [ ] Migrate to MongoDB Atlas Vector Search
- [ ] Add query expansion
- [ ] Implement hybrid scoring
- [ ] Add caching layer

### Phase 3: Enhancement (ongoing)
- [ ] A/B testing framework
- [ ] Analytics & monitoring
- [ ] Personalized ranking
- [ ] Feedback loop for relevance

---

*TÃ i liá»‡u Ä‘Æ°á»£c táº¡o: 08/01/2026*
*PhiÃªn báº£n: 1.0*
