# H∆∞·ªõng D·∫´n Deploy ML Services l√™n Render.com

## T·ªïng Quan

ML Services API cung c·∫•p 7 d·ªãch v·ª• ML/AI:

| Service | M√¥ t·∫£ | Endpoints |
|---------|-------|-----------|
| **Prophet** | D·ª± b√°o t·ªìn kho time-series | `/predict`, `/models` |
| **Sentiment** | Ph√¢n t√≠ch c·∫£m x√∫c ti·∫øng Vi·ªát | `/sentiment/analyze` |
| **Churn** | D·ª± ƒëo√°n r·ªùi b·ªè kh√°ch h√†ng | `/churn/predict`, `/churn/at-risk` |
| **Pricing** | ƒê·ªãnh gi√° ƒë·ªông | `/pricing/recommend` |
| **Contractors** | G·ª£i √Ω nh√† th·∫ßu | `/contractors/match` |
| **Market** | Ph√¢n t√≠ch xu h∆∞·ªõng th·ªã tr∆∞·ªùng | `/market/trends`, `/market/forecast` |
| **Search** | T√¨m ki·∫øm ng·ªØ nghƒ©a | `/search/semantic` |

---

## C·∫•u tr√∫c th∆∞ m·ª•c c·∫ßn upload

```
ml-service/
‚îú‚îÄ‚îÄ app.py                      # Main Flask server
‚îú‚îÄ‚îÄ requirements.txt            # Python dependencies
‚îú‚îÄ‚îÄ Procfile                    # L·ªánh kh·ªüi ƒë·ªông cho Render
‚îú‚îÄ‚îÄ .python-version             # Version Python
‚îÇ
‚îú‚îÄ‚îÄ # Core ML Services
‚îú‚îÄ‚îÄ sentiment_analysis.py       # Sentiment Analysis
‚îú‚îÄ‚îÄ churn_prediction.py         # Customer Churn Prediction
‚îú‚îÄ‚îÄ dynamic_pricing.py          # Dynamic Pricing
‚îú‚îÄ‚îÄ contractor_matching.py      # Contractor Matching
‚îú‚îÄ‚îÄ market_trend.py             # Market Trend Analysis
‚îú‚îÄ‚îÄ semantic_search.py          # Semantic Search
‚îú‚îÄ‚îÄ vietnamese_lexicon.py       # Vietnamese NLP Lexicon
‚îÇ
‚îú‚îÄ‚îÄ # Prophet (legacy)
‚îú‚îÄ‚îÄ train_prophet.py            # Script training Prophet
‚îú‚îÄ‚îÄ predict_server.py           # Prophet-only server (legacy)
‚îÇ
‚îî‚îÄ‚îÄ models/                     # Trained models directory
```

---

## Deploy t·ª´ GitHub (ƒê·ªÅ xu·∫•t)

### B∆∞·ªõc 1: Push code l√™n GitHub
```bash
# T·∫°o repo m·ªõi tr√™n GitHub, sau ƒë√≥:
cd scripts/ml-service
git init
git add .
git commit -m "ML Services API v2.0"
git remote add origin https://github.com/YOUR_USERNAME/ml-services.git
git push -u origin main
```

### B∆∞·ªõc 2: T·∫°o Web Service tr√™n Render
1. V√†o [render.com](https://render.com) ‚Üí Dashboard
2. Click **"New +"** ‚Üí **"Web Service"**
3. Ch·ªçn **"Connect a repository"** ‚Üí Ch·ªçn repo v·ª´a t·∫°o
4. C·∫•u h√¨nh:
   - **Name**: `ml-services-api`
   - **Region**: Singapore (g·∫ßn VN nh·∫•t)
   - **Branch**: `main`
   - **Runtime**: `Python 3`
   - **Build Command**: `pip install -r requirements.txt`
   - **Start Command**: `gunicorn app:app`
5. Click **"Create Web Service"**

### B∆∞·ªõc 3: C·∫•u h√¨nh Environment Variables

Th√™m c√°c bi·∫øn m√¥i tr∆∞·ªùng tr√™n Render Dashboard:

```env
# Required for Semantic Search
GEMINI_API_KEY=your-gemini-api-key

# Optional for MongoDB connection
DATABASE_URL=mongodb+srv://...your-mongodb-connection-string...
```

### B∆∞·ªõc 4: L·∫•y URL v√† c·∫•u h√¨nh Vercel
- Render s·∫Ω c·∫•p URL d·∫°ng: `https://ml-services-api.onrender.com`
- Th√™m v√†o `.env` c·ªßa Next.js project:
```env
ML_SERVICES_URL=https://ml-services-api.onrender.com
PROPHET_SERVER_URL=https://ml-services-api.onrender.com
```

---

## API Endpoints

### Health Check
```bash
curl https://your-app.onrender.com/health
```

### Sentiment Analysis
```bash
curl -X POST https://your-app.onrender.com/sentiment/analyze \
  -H "Content-Type: application/json" \
  -d '{"text": "Giao h√†ng nhanh, ch·∫•t l∆∞·ª£ng t·ªët!"}'
```

### Churn Prediction
```bash
curl -X POST https://your-app.onrender.com/churn/predict \
  -H "Content-Type: application/json" \
  -d '{
    "customer_id": "C001",
    "orders_12m": 8,
    "total_spent_12m": 45000000,
    "recent_3m_spent": 5000000,
    "previous_3m_spent": 20000000
  }'
```

### Dynamic Pricing
```bash
curl -X POST https://your-app.onrender.com/pricing/recommend \
  -H "Content-Type: application/json" \
  -d '{
    "productId": "prod_001",
    "productName": "Xi mƒÉng Holcim",
    "basePrice": 95000,
    "cost": 78000,
    "currentStock": 500,
    "avgDailySales": 15,
    "demandIndex": 1.2
  }'
```

### Contractor Matching
```bash
curl -X POST https://your-app.onrender.com/contractors/match \
  -H "Content-Type: application/json" \
  -d '{
    "project": {
      "title": "X√¢y nh√† 2 t·∫ßng",
      "description": "C·∫ßn th·ª£ h·ªì gi·ªèi",
      "requirements": ["th·ª£ h·ªì", "x√¢y d·ª±ng"],
      "city": "Bi√™n H√≤a"
    },
    "contractors": [
      {"id": "C001", "displayName": "Nguy·ªÖn VƒÉn A", "skills": ["th·ª£ h·ªì"], "avgRating": 4.5}
    ]
  }'
```

### Market Trends
```bash
curl https://your-app.onrender.com/market/trends?category=cement&period=30
```

### Semantic Search
```bash
# First, index products
curl -X POST https://your-app.onrender.com/search/index \
  -H "Content-Type: application/json" \
  -d '{"products": [{"id": "1", "name": "Xi mƒÉng Holcim", "category": "cement"}]}'

# Then search
curl -X POST https://your-app.onrender.com/search/semantic \
  -H "Content-Type: application/json" \
  -d '{"query": "xi mƒÉng ch·ªëng th·∫•m"}'
```

---

## L∆∞u √Ω quan tr·ªçng

### ‚ö†Ô∏è Free tier c·ªßa Render:
- **Spin down sau 15 ph√∫t kh√¥ng ho·∫°t ƒë·ªông**
- Request ƒë·∫ßu ti√™n sau spin down s·∫Ω ch·∫≠m (~30-60s)
- Gi·ªõi h·∫°n 750 gi·ªù/th√°ng

### üí° Gi·∫£i ph√°p:
1. D√πng Paid tier ($7/th√°ng) ƒë·ªÉ kh√¥ng spin down
2. Set up GitHub Actions ping m·ªói 14 ph√∫t
3. Ch·∫•p nh·∫≠n cold start (Next.js s·∫Ω fallback n·∫øu timeout)

### üìä Memory Requirements:
- **Free Tier**: 512MB RAM - ƒë·ªß cho t·∫•t c·∫£ services
- Prophet models: ~50-100MB m·ªói model
- Semantic Search vector store: ~10-50MB t√πy s·ªë products

---

## GitHub Actions Keep-Warm (Optional)

T·∫°o file `.github/workflows/keep-warm.yml`:

```yaml
name: Keep ML Services Warm

on:
  schedule:
    - cron: '*/14 * * * *'  # Every 14 minutes

jobs:
  ping:
    runs-on: ubuntu-latest
    steps:
      - name: Ping ML Services
        run: |
          curl -f https://ml-services-api.onrender.com/health || true
```

---

## K·∫øt n·ªëi v·ªõi Vercel

1. Th√™m environment variables tr√™n Vercel:
```env
ML_SERVICES_URL=https://ml-services-api.onrender.com
PROPHET_SERVER_URL=https://ml-services-api.onrender.com
GEMINI_API_KEY=your-gemini-api-key
```

2. Redeploy Next.js app

3. S·ª≠ d·ª•ng trong code:
```typescript
const ML_URL = process.env.ML_SERVICES_URL || 'http://localhost:5000';

// G·ªçi sentiment analysis
const response = await fetch(`${ML_URL}/sentiment/analyze`, {
  method: 'POST',
  headers: { 'Content-Type': 'application/json' },
  body: JSON.stringify({ text: reviewText })
});
```

---

## Troubleshooting

### L·ªói "underthesea not found"
```bash
# Th√™m v√†o requirements.txt n·∫øu ch∆∞a c√≥
underthesea>=6.8.0
```

### L·ªói "prophet install failed"
Prophet c·∫ßn CMake v√† compiler. Tr√™n Render th∆∞·ªùng OK, nh∆∞ng n·∫øu l·ªói th·ª≠:
```bash
# Th√™m v√†o Build Command
pip install pystan==2.19.1.1 && pip install -r requirements.txt
```

### L·ªói "Memory limit exceeded"
- Gi·∫£m s·ªë models loaded c√πng l√∫c
- Upgrade l√™n Paid tier v·ªõi RAM l·ªõn h∆°n

---

*T√†i li·ªáu c·∫≠p nh·∫≠t: 09/01/2026*
*Version: 2.0.0*
